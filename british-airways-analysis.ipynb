{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "982f90f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T03:54:13.322811Z",
     "iopub.status.busy": "2023-06-29T03:54:13.322263Z",
     "iopub.status.idle": "2023-06-29T03:54:13.580224Z",
     "shell.execute_reply": "2023-06-29T03:54:13.578953Z"
    },
    "papermill": {
     "duration": 0.266994,
     "end_time": "2023-06-29T03:54:13.583141",
     "exception": false,
     "start_time": "2023-06-29T03:54:13.316147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2bdc55a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T03:54:13.592532Z",
     "iopub.status.busy": "2023-06-29T03:54:13.591776Z",
     "iopub.status.idle": "2023-06-29T03:54:14.760841Z",
     "shell.execute_reply": "2023-06-29T03:54:14.759557Z"
    },
    "papermill": {
     "duration": 1.176674,
     "end_time": "2023-06-29T03:54:14.763622",
     "exception": false,
     "start_time": "2023-06-29T03:54:13.586948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "   ---> 10 total reviews\n"
     ]
    }
   ],
   "source": [
    "# Set the URL of the paginated webpage that you want to scrape\n",
    "url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "\n",
    "# Initialize an empty list to store the data that you scrape\n",
    "data = []\n",
    "\n",
    "# Setting the initial page number and the increment that you want to use to paginate through the webpage\n",
    "page_num = 1\n",
    "page_incr = 1\n",
    "page_size = 10\n",
    "# maximum number of pages to be scraped\n",
    "max_pages = 1\n",
    "\n",
    "# Set the URL of the webpage to be scraped \n",
    "paginated_url = f\"{url}/page/{page_num}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "# A while loop to paginate through the webpage and scrape the data\n",
    "while page_num <= max_pages:\n",
    "\n",
    "    print(f\"Scraping page {page_num}\")\n",
    "\n",
    "    # A GET request to the paginated URL\n",
    "    response = requests.get(paginated_url)\n",
    "\n",
    "    # Parsing the response using BeautifulSoup\n",
    "    parsed_content = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Finding all the elements on the page that contain the data to be scraped\n",
    "    elements_rating = parsed_content.find_all(lambda tag: tag.name == \"div\" and tag.get(\"class\") == [\"rating-10\"])\n",
    "    elements_body = parsed_content.find_all(\"div\",class_ = \"body\")\n",
    "    elements_stat = parsed_content.find_all(\"div\",class_ =\"review-stats\")\n",
    "    body_len = len(elements_body)\n",
    "\n",
    "    for i in range(body_len):\n",
    "        element = elements_body[i]\n",
    "        element_r = elements_rating[i]\n",
    "        element_s = elements_stat[i]\n",
    "        \n",
    "        header = element.find(\"h2\",class_ = \"text_header\").text.replace(\"\\n\", \" \")\n",
    "        sub_header = element.find(\"h3\",class_ = \"text_sub_header\").text.replace(\"\\n\", \" \")\n",
    "        content = element.find(\"div\",class_ = \"text_content\").text.replace(\"\\n\", \" \")\n",
    "        score = element_r.find(\"span\", itemprop =\"ratingValue\").text.replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "        table = element_s.find(\"table\", class_ =\"review-ratings\")\n",
    "        titles = []\n",
    "        contents = []\n",
    "#         for i in table.find_all(\"tr\"):\n",
    "#             values = i.find_all(\"td\")\n",
    "#             title = values[0].text.replace(\"\\n\", \" \")\n",
    "#             titles.append(title)\n",
    "#             content = values[1].text.replace(\"\\n\", \" \")\n",
    "#             contents.append(content)\n",
    "                 \n",
    "        \n",
    "        #convert to dataframe\n",
    "        data.append([header,sub_header,content, score])\n",
    "        df = pd.DataFrame(data)\n",
    "        df.columns = [\"header\",\"sub_header\",\"content\",\"score\"]\n",
    "        \n",
    "        #table of rating stat\n",
    "        for i in table.find_all(\"tr\"):\n",
    "            values = i.find_all(\"td\")\n",
    "            title = values[0].text.replace(\"\\n\", \" \")\n",
    "            content = values[1].text.replace(\"\\n\", \" \")\n",
    "            df[title] = content\n",
    "        \n",
    "        \n",
    "    # Looping through the elements and extract the data that you want to scrape\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # Increasing the page number and setting the paginated URL to the new page\n",
    "    page_num += page_incr\n",
    "    paginated_url = f\"{url}/page/{page_num}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    print(f\"   ---> {len(data)} total reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e995d05d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T03:54:14.773504Z",
     "iopub.status.busy": "2023-06-29T03:54:14.773116Z",
     "iopub.status.idle": "2023-06-29T03:54:14.808201Z",
     "shell.execute_reply": "2023-06-29T03:54:14.807059Z"
    },
    "papermill": {
     "duration": 0.043278,
     "end_time": "2023-06-29T03:54:14.810703",
     "exception": false,
     "start_time": "2023-06-29T03:54:14.767425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>header</th>\n",
       "      <th>sub_header</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>Aircraft</th>\n",
       "      <th>Type Of Traveller</th>\n",
       "      <th>Seat Type</th>\n",
       "      <th>Route</th>\n",
       "      <th>Date Flown</th>\n",
       "      <th>Seat Comfort</th>\n",
       "      <th>Cabin Staff Service</th>\n",
       "      <th>Food &amp; Beverages</th>\n",
       "      <th>Ground Service</th>\n",
       "      <th>Value For Money</th>\n",
       "      <th>Recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"stated it is not their fault\"</td>\n",
       "      <td>N Beale (United Kingdom) 27th June 2023</td>\n",
       "      <td>✅ Trip Verified |  After travelling London to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Boeing 737</td>\n",
       "      <td>Couple Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>London Heathrow to Kalamata</td>\n",
       "      <td>June 2023</td>\n",
       "      <td>12345</td>\n",
       "      <td>12345</td>\n",
       "      <td>12345</td>\n",
       "      <td>12345</td>\n",
       "      <td>12345</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"luggage was mis-tagged in Dallas\"</td>\n",
       "      <td>T Casey (United States) 27th June 2023</td>\n",
       "      <td>✅ Trip Verified |  My luggage was mis-tagged i...</td>\n",
       "      <td>1</td>\n",
       "      <td>Boeing 737</td>\n",
       "      <td>Couple Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>London Heathrow to Kalamata</td>\n",
       "      <td>June 2023</td>\n",
       "      <td>12345</td>\n",
       "      <td>12345</td>\n",
       "      <td>12345</td>\n",
       "      <td>12345</td>\n",
       "      <td>12345</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"The airline lost my luggage\"</td>\n",
       "      <td>Paige Boet (United States) 25th June 2023</td>\n",
       "      <td>✅ Trip Verified |  The airline lost my luggage...</td>\n",
       "      <td>1</td>\n",
       "      <td>Boeing 737</td>\n",
       "      <td>Couple Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>London Heathrow to Kalamata</td>\n",
       "      <td>June 2023</td>\n",
       "      <td>12345</td>\n",
       "      <td>12345</td>\n",
       "      <td>12345</td>\n",
       "      <td>12345</td>\n",
       "      <td>12345</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"fully refunded by our travel insurance\"</td>\n",
       "      <td>S Layne (United States) 25th June 2023</td>\n",
       "      <td>✅ Trip Verified |  We booked on the BA website...</td>\n",
       "      <td>1</td>\n",
       "      <td>Boeing 737</td>\n",
       "      <td>Couple Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>London Heathrow to Kalamata</td>\n",
       "      <td>June 2023</td>\n",
       "      <td>12345</td>\n",
       "      <td>12345</td>\n",
       "      <td>12345</td>\n",
       "      <td>12345</td>\n",
       "      <td>12345</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"no boarding drinks provided\"</td>\n",
       "      <td>E Lanewoski (United Kingdom) 25th June 2023</td>\n",
       "      <td>✅ Trip Verified |  First time flying with BA b...</td>\n",
       "      <td>2</td>\n",
       "      <td>Boeing 737</td>\n",
       "      <td>Couple Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>London Heathrow to Kalamata</td>\n",
       "      <td>June 2023</td>\n",
       "      <td>12345</td>\n",
       "      <td>12345</td>\n",
       "      <td>12345</td>\n",
       "      <td>12345</td>\n",
       "      <td>12345</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     header  \\\n",
       "0            \"stated it is not their fault\"   \n",
       "1        \"luggage was mis-tagged in Dallas\"   \n",
       "2             \"The airline lost my luggage\"   \n",
       "3  \"fully refunded by our travel insurance\"   \n",
       "4             \"no boarding drinks provided\"   \n",
       "\n",
       "                                      sub_header  \\\n",
       "0        N Beale (United Kingdom) 27th June 2023   \n",
       "1         T Casey (United States) 27th June 2023   \n",
       "2      Paige Boet (United States) 25th June 2023   \n",
       "3         S Layne (United States) 25th June 2023   \n",
       "4    E Lanewoski (United Kingdom) 25th June 2023   \n",
       "\n",
       "                                             content score    Aircraft  \\\n",
       "0  ✅ Trip Verified |  After travelling London to ...     1  Boeing 737   \n",
       "1  ✅ Trip Verified |  My luggage was mis-tagged i...     1  Boeing 737   \n",
       "2  ✅ Trip Verified |  The airline lost my luggage...     1  Boeing 737   \n",
       "3  ✅ Trip Verified |  We booked on the BA website...     1  Boeing 737   \n",
       "4  ✅ Trip Verified |  First time flying with BA b...     2  Boeing 737   \n",
       "\n",
       "  Type Of Traveller      Seat Type                        Route Date Flown  \\\n",
       "0    Couple Leisure  Economy Class  London Heathrow to Kalamata  June 2023   \n",
       "1    Couple Leisure  Economy Class  London Heathrow to Kalamata  June 2023   \n",
       "2    Couple Leisure  Economy Class  London Heathrow to Kalamata  June 2023   \n",
       "3    Couple Leisure  Economy Class  London Heathrow to Kalamata  June 2023   \n",
       "4    Couple Leisure  Economy Class  London Heathrow to Kalamata  June 2023   \n",
       "\n",
       "  Seat Comfort Cabin Staff Service Food & Beverages Ground Service  \\\n",
       "0        12345               12345            12345          12345   \n",
       "1        12345               12345            12345          12345   \n",
       "2        12345               12345            12345          12345   \n",
       "3        12345               12345            12345          12345   \n",
       "4        12345               12345            12345          12345   \n",
       "\n",
       "  Value For Money Recommended  \n",
       "0           12345         yes  \n",
       "1           12345         yes  \n",
       "2           12345         yes  \n",
       "3           12345         yes  \n",
       "4           12345         yes  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27785f25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T03:54:14.821610Z",
     "iopub.status.busy": "2023-06-29T03:54:14.820457Z",
     "iopub.status.idle": "2023-06-29T03:54:15.341343Z",
     "shell.execute_reply": "2023-06-29T03:54:15.339842Z"
    },
    "papermill": {
     "duration": 0.529267,
     "end_time": "2023-06-29T03:54:15.344127",
     "exception": false,
     "start_time": "2023-06-29T03:54:14.814860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "   ---> 0 total reviews\n",
      "                                     header  \\\n",
      "0            \"stated it is not their fault\"   \n",
      "1        \"luggage was mis-tagged in Dallas\"   \n",
      "2             \"The airline lost my luggage\"   \n",
      "3  \"fully refunded by our travel insurance\"   \n",
      "4             \"no boarding drinks provided\"   \n",
      "\n",
      "                                      sub_header  \\\n",
      "0        N Beale (United Kingdom) 27th June 2023   \n",
      "1         T Casey (United States) 27th June 2023   \n",
      "2      Paige Boet (United States) 25th June 2023   \n",
      "3         S Layne (United States) 25th June 2023   \n",
      "4    E Lanewoski (United Kingdom) 25th June 2023   \n",
      "\n",
      "                                             content score  Aircraft  \\\n",
      "0  ✅ Trip Verified |  After travelling London to ...     1  A321 neo   \n",
      "1  ✅ Trip Verified |  My luggage was mis-tagged i...     1  A321 neo   \n",
      "2  ✅ Trip Verified |  The airline lost my luggage...     1  A321 neo   \n",
      "3  ✅ Trip Verified |  We booked on the BA website...     1  A321 neo   \n",
      "4  ✅ Trip Verified |  First time flying with BA b...     2  A321 neo   \n",
      "\n",
      "  Type Of Traveller       Seat Type               Route Date Flown  \\\n",
      "0      Solo Leisure  Business Class  Heathrow to Bodrum  June 2023   \n",
      "1      Solo Leisure  Business Class  Heathrow to Bodrum  June 2023   \n",
      "2      Solo Leisure  Business Class  Heathrow to Bodrum  June 2023   \n",
      "3      Solo Leisure  Business Class  Heathrow to Bodrum  June 2023   \n",
      "4      Solo Leisure  Business Class  Heathrow to Bodrum  June 2023   \n",
      "\n",
      "  Seat Comfort Cabin Staff Service Food & Beverages Ground Service  \\\n",
      "0        12345               12345            12345          12345   \n",
      "1        12345               12345            12345          12345   \n",
      "2        12345               12345            12345          12345   \n",
      "3        12345               12345            12345          12345   \n",
      "4        12345               12345            12345          12345   \n",
      "\n",
      "  Value For Money Recommended Inflight Entertainment Wifi & Connectivity  \n",
      "0           12345          no                  12345               12345  \n",
      "1           12345          no                  12345               12345  \n",
      "2           12345          no                  12345               12345  \n",
      "3           12345          no                  12345               12345  \n",
      "4           12345          no                  12345               12345  \n"
     ]
    }
   ],
   "source": [
    "# Set the URL of the paginated webpage that you want to scrape\n",
    "url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "\n",
    "# Initialize an empty list to store the data that you scrape\n",
    "data = []\n",
    "\n",
    "\n",
    "# Setting the initial page number and the increment that you want to use to paginate through the webpage\n",
    "page_num = 1\n",
    "page_incr = 1\n",
    "page_size = 5\n",
    "# maximum number of pages to be scraped\n",
    "max_pages = 1\n",
    "\n",
    "# Set the URL of the webpage to be scraped \n",
    "paginated_url = f\"{url}/page/{page_num}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "# A while loop to paginate through the webpage and scrape the data\n",
    "\n",
    "while page_num <= max_pages:\n",
    "\n",
    "    print(f\"Scraping page {page_num}\")\n",
    "\n",
    "    # A GET request to the paginated URL\n",
    "    response = requests.get(paginated_url)\n",
    "\n",
    "    # Parsing the response using BeautifulSoup\n",
    "    parsed_content = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Finding all the elements on the page that contain the data to be scraped\n",
    "    elements = parsed_content.find_all(\"div\",class_ = \"body\")\n",
    "\n",
    "    # Looping through the elements and extract the data that you want to scrape\n",
    "    \n",
    "    for element in elements:\n",
    "        # Obtain information from tag <table>\n",
    "        table = element.find(\"table\", class_ =\"review-ratings\")\n",
    "        # Obtain every title of columns with tag <tr>\n",
    "        headers = []\n",
    "        header_list = []\n",
    "        \n",
    "        for i in table.find_all(\"tr\"):\n",
    "            values = i.find_all(\"td\")\n",
    "            title = values[0].text.replace(\"\\n\", \" \")\n",
    "            content = values[1].text.replace(\"\\n\", \" \")\n",
    "            df[title] = content\n",
    "    \n",
    "        \n",
    "\n",
    "            \n",
    "    \n",
    "\n",
    "            \n",
    "# Increasing the page number and setting the paginated URL to the new page\n",
    "    page_num += page_incr\n",
    "    paginated_url = f\"{url}/page/{page_num}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "    print(f\"   ---> {len(headers)} total reviews\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38f33f3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T03:54:15.355173Z",
     "iopub.status.busy": "2023-06-29T03:54:15.354416Z",
     "iopub.status.idle": "2023-06-29T03:54:15.360980Z",
     "shell.execute_reply": "2023-06-29T03:54:15.359616Z"
    },
    "papermill": {
     "duration": 0.014707,
     "end_time": "2023-06-29T03:54:15.363361",
     "exception": false,
     "start_time": "2023-06-29T03:54:15.348654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criteria_repeated = []\n",
    "for i in headers:\n",
    "    criteria_repeated.append(i[0])\n",
    "criteria = set(criteria_repeated)\n",
    "for i in criteria:\n",
    "    print(type(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45a86c50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T03:54:15.374013Z",
     "iopub.status.busy": "2023-06-29T03:54:15.373612Z",
     "iopub.status.idle": "2023-06-29T03:54:15.380293Z",
     "shell.execute_reply": "2023-06-29T03:54:15.378989Z"
    },
    "papermill": {
     "duration": 0.014875,
     "end_time": "2023-06-29T03:54:15.382749",
     "exception": false,
     "start_time": "2023-06-29T03:54:15.367874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "criteria_repeated = []\n",
    "for i in headers:\n",
    "    criteria_repeated.append(i[0])\n",
    "criteria = set(criteria_repeated)\n",
    "print(criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3c2e59c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T03:54:15.394010Z",
     "iopub.status.busy": "2023-06-29T03:54:15.393366Z",
     "iopub.status.idle": "2023-06-29T03:54:15.401808Z",
     "shell.execute_reply": "2023-06-29T03:54:15.400525Z"
    },
    "papermill": {
     "duration": 0.016787,
     "end_time": "2023-06-29T03:54:15.403993",
     "exception": false,
     "start_time": "2023-06-29T03:54:15.387206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criteria_repeated = []\n",
    "for i in headers:\n",
    "    criteria_repeated.append(i[0])\n",
    "criteria = set(criteria_repeated)\n",
    "criteria"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16.423101,
   "end_time": "2023-06-29T03:54:16.333155",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-29T03:53:59.910054",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
